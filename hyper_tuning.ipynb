{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preliminary operations",
   "id": "54612962a057183f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "seed = 123\n",
    "tf.keras.utils.set_random_seed(seed)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%run utils.ipynb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3276d6ca2d9d09d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%run preprocessing.ipynb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf7aeeca1663d92",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%run preparation.ipynb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2d209f940fad000",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "%run training_transformer.ipynb",
   "metadata": {
    "collapsed": false
   },
   "id": "d76ed7a782e545bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%run predict.ipynb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d105ae8cb14be939",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b94889c11cf4d982"
  },
  {
   "cell_type": "code",
   "source": [
    "data_path = 'datasets/raw/sf_normal_final_indicators_93600.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "number_of_features = len(df.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45dc6db3638695cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fab3ed5577fa5e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# List of parameters for preprocessing\n",
    "params = [\n",
    "    ['timestamp', 'rides_requested',  'rides_accepted', 'rides_not_served', 'rides_canceled', 'rides_completed', 'pending_customers', 'active_customers', 'responding_drivers'],\n",
    "    False, # ratio\n",
    "    False, # smoothing\n",
    "    False, # collinearity\n",
    "    False, # log\n",
    "    300, # aggregation\n",
    "    False, # statistics\n",
    "    1, # differencing\n",
    "    True, # seasonality\n",
    "    True # normalize\n",
    "]\n",
    "scaler_path = f\"df_{params[0]}_{params[1]}_{params[2]}_{params[3]}_{params[4]}_{params[5]}_{params[6]}_{params[7]}_{params[8]}_{params[9]}_scaler.pkl\"\n",
    "\n",
    "# Apply preprocessing strategy according to previous parameters selection\n",
    "df_ = copy.deepcopy(df)\n",
    "df_proc, scaler = preprocessing(df_,\n",
    "                        columns_to_remove = params[0],\n",
    "                        ratio = params[1],\n",
    "                        smoothing = params[2],\n",
    "                        collinearity = params[3],\n",
    "                        log = params[4],\n",
    "                        aggregation = params[5],\n",
    "                        statistics = params[6],\n",
    "                        differencing = params[7],\n",
    "                        seasonality = params[8],\n",
    "                        normalize = params[9],\n",
    "                        load_scaler = False,\n",
    "                        save = False,\n",
    "                        continual = False)"
   ],
   "id": "7040ca1d63589888",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Hyperparameter Tuning",
   "metadata": {
    "collapsed": false
   },
   "id": "47671be73e17919c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the hyperparameter search space\n",
    "param_grid_transformer = {\n",
    "    'n_heads': [4, 8],\n",
    "    'd_model': [64, 128],\n",
    "    'feed_forward_size': [128, 256, 512],\n",
    "    'n_layers_encoder': [1, 2],\n",
    "    'n_layers_decoder': [1, 2],\n",
    "    'learning_rate': [0.0001, 0.001],\n",
    "    'dropout_rate': [0.0, 0.2],\n",
    "    'batch_size': [32, 64],\n",
    "}"
   ],
   "id": "1a7be9edf829da1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def hyper_tuning_transformer(data, window_size, param_grid):\n",
    "\n",
    "    results = []\n",
    "    count = 0\n",
    "\n",
    "    # Grid Search\n",
    "    for hyperp in ParameterGrid(param_grid):\n",
    "\n",
    "        # Compute only meaningful combinations\n",
    "        if (hyperp['n_heads'] == 4 and hyperp['d_model'] == 64 and hyperp['feed_forward_size'] in [128, 256]) or (hyperp['n_heads'] == 4 and hyperp['d_model'] == 128 and hyperp['feed_forward_size'] in [256, 512]) or (hyperp['n_heads'] == 8 and hyperp['d_model'] == 128 and hyperp['feed_forward_size'] in [256, 512]):\n",
    "\n",
    "            if hyperp['n_layers_encoder'] == hyperp['n_layers_decoder']:\n",
    "                count += 1\n",
    "                print(f\"Combination: {count}, testing the following hyperparameters: {hyperp}\")\n",
    "\n",
    "                train_set = create_sequences(data, window_size, 0)\n",
    "                history, model = training_transformer_autoencoder(train_set,\n",
    "                                    train_set,\n",
    "                                    n_heads = hyperp['n_heads'],\n",
    "                                    d_model = hyperp['d_model'],\n",
    "                                    num_encoder_layers = hyperp['n_layers_encoder'],\n",
    "                                    num_decoder_layers = hyperp['n_layers_decoder'],\n",
    "                                    feed_forward_dim = hyperp['feed_forward_size'],\n",
    "                                    dropout_rate = hyperp['dropout_rate'],\n",
    "                                    learning_rate = hyperp['learning_rate'],\n",
    "                                    n_epochs = 500,\n",
    "                                    batch_size = hyperp['batch_size'],\n",
    "                                    window_size = window_size,\n",
    "                                    metric = 'mse',\n",
    "                                    plot = False,\n",
    "                                    save = False)\n",
    "                # Save each score\n",
    "                score = np.min(history.history['val_loss'])\n",
    "                results.append({\"params\": hyperp, \"score\": score})\n",
    "                print(f\"Score for params {hyperp}: {score}\\n\")\n",
    "\n",
    "    print(f\"Total number of combinations: {count}\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('hyper_tuning/transformer_performance_w_size_' + str(window_size) + '.csv', index = False)"
   ],
   "id": "24979d349f4ce64b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "windows = [20, 30]\n",
    "for window in windows:\n",
    "    hyper_tuning_transformer(df_proc, window, param_grid_transformer)"
   ],
   "id": "e8e6aa17de9f2af5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hyper_tuning_transformer(df_proc, 20, param_grid_transformer)",
   "id": "ac691536aa76d277",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T11:28:13.928537Z",
     "start_time": "2025-01-26T11:28:13.910648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_scores_20 = pd.read_csv('hyper_tuning/transformer_performance_w_size_20.csv')\n",
    "df_scores_30 = pd.read_csv('hyper_tuning/transformer_performance_w_size_30.csv')\n",
    "final_df_scores = pd.concat([df_scores_20, df_scores_30])\n",
    "final_df_scores.to_csv('hyper_tuning/hyper_tuning_transformer_performance.csv', index = False)\n",
    "final_df_scores = final_df_scores.sort_values(by = 'score', ascending = True)\n",
    "print('Best combination: ' + str(final_df_scores['params'].iloc[0]) + ', loss: ' + str(final_df_scores['score'].iloc[0]))"
   ],
   "id": "aadef613176f02fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best combination: {'batch_size': 32, 'd_model': 128, 'dropout_rate': 0.2, 'feed_forward_size': 256, 'learning_rate': 0.0001, 'n_heads': 8, 'n_layers_decoder': 1, 'n_layers_encoder': 1}, loss: 9.77929012151435e-05\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
