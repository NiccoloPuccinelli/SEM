{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-23T09:05:48.505070Z",
     "start_time": "2024-01-23T09:05:45.438409Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%run utils.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T09:05:48.605864Z",
     "start_time": "2024-01-23T09:05:48.502788Z"
    }
   },
   "id": "601d6e1fae9ad1ab",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def training_dense(train_data,\n",
    "                   val_data,\n",
    "                   n_layers_encoder = 1,\n",
    "                   n_layers_decoder = 1,\n",
    "                   hidden_units = [64, 32, 32, 64],\n",
    "                   activation_hidden = 'relu',\n",
    "                   activation_dense = 'sigmoid',\n",
    "                   dropout_rate = 0,\n",
    "                   learning_rate = 0.001,\n",
    "                   n_epochs = 500,\n",
    "                   metric = 'mse',\n",
    "                   batch_size = 32,\n",
    "                   plot = True,\n",
    "                   save = True):\n",
    "\n",
    "    number_of_features = train_data.shape[1]\n",
    "    opt = Adam(learning_rate = learning_rate)\n",
    "\n",
    "    # Build model\n",
    "    inputs = Input(shape = (number_of_features))\n",
    "    flattened = Flatten()(inputs)\n",
    "    # Encoder\n",
    "    encoded = Dense(hidden_units[0], activation = activation_hidden)(flattened)\n",
    "    for i in range(0, n_layers_encoder):\n",
    "        encoded = Dense(hidden_units[i], activation = activation_hidden)(encoded)\n",
    "        if dropout_rate != 0:\n",
    "            encoded = Dropout(dropout_rate)(encoded)\n",
    "    # Decoder\n",
    "    decoded = Dense(hidden_units[n_layers_encoder+1], activation = activation_hidden)(encoded)\n",
    "    if dropout_rate != 0:\n",
    "        decoded = Dropout(dropout_rate)(decoded)\n",
    "    for i in range(0, n_layers_decoder):\n",
    "        decoded = Dense(hidden_units[n_layers_encoder+i+2], activation = activation_hidden)(decoded)\n",
    "        if dropout_rate != 0:\n",
    "            decoded = Dropout(dropout_rate)(decoded)\n",
    "    decoded = Dense(number_of_features, activation = activation_dense)(decoded)\n",
    "\n",
    "    loss_metric = tf.keras.losses.MeanSquaredError()\n",
    "    if metric == 'mse':\n",
    "        loss_metric = tf.keras.losses.MeanSquaredError()\n",
    "    elif metric == 'mae':\n",
    "        loss_metric = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "    # Compile model\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer = opt, loss = loss_metric)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 100, verbose = 1, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "    # Train model\n",
    "    if val_data is not None:\n",
    "        history = autoencoder.fit(\n",
    "            train_data, train_data,\n",
    "            epochs = n_epochs,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = False,\n",
    "            validation_data = (val_data, val_data),\n",
    "            callbacks = [early_stopping]\n",
    "        )\n",
    "    else:\n",
    "        history = autoencoder.fit(\n",
    "            train_data, train_data,\n",
    "            epochs = n_epochs,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = False\n",
    "        )\n",
    "    \n",
    "    model_path = 'dense/' + str(n_layers_encoder) + '_' + str(n_layers_decoder) + '_' + str(hidden_units[0]) + '_' + str(hidden_units[len(hidden_units)-1]) + '_' + str(activation_hidden) + '_' + str(activation_dense) + '_' + str(dropout_rate).replace('.', '') + '_' + str(learning_rate).replace('.', '') + '_' + str(n_epochs) + '_' + str(metric) + '_' + str(batch_size)\n",
    "\n",
    "    # Save history\n",
    "    if plot:\n",
    "        plt.figure(figsize = (10, 5))\n",
    "        plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        plt.tight_layout()\n",
    "        loss_save_path = 'losses/' + model_path\n",
    "        plt.savefig(loss_save_path + '.png')\n",
    "        plt.close()\n",
    "        \n",
    "    # Save model\n",
    "    if save:\n",
    "        model_save_path = 'models/' + model_path + '.pkl'\n",
    "        with open(model_save_path, 'wb') as file:\n",
    "            pickle.dump(autoencoder, file)\n",
    "\n",
    "    return history, autoencoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "901c61c20769837",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
