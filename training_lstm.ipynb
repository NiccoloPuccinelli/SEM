{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-02T10:45:25.680077Z",
     "start_time": "2024-02-02T10:45:25.676722Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from math import sqrt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Dropout, TimeDistributed\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "seed = 123\n",
    "tf.keras.utils.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%run utils.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T14:56:07.814200Z",
     "start_time": "2024-02-02T14:56:07.808959Z"
    }
   },
   "id": "601d6e1fae9ad1ab",
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def training_lstm(train_data,\n",
    "                  val_data,\n",
    "                  n_layers_encoder = 1,\n",
    "                  n_layers_decoder = 1,\n",
    "                  hidden_units = [64, 32, 32, 64],\n",
    "                  activation_hidden = 'relu',\n",
    "                  activation_dense = 'sigmoid',\n",
    "                  dropout_rate = 0,\n",
    "                  learning_rate = 0.001,\n",
    "                  n_epochs = 500,\n",
    "                  metric = 'mse',\n",
    "                  batch_size = 32,\n",
    "                  window_size = 20,\n",
    "                  plot = True,\n",
    "                  save = True):\n",
    "\n",
    "    number_of_features = train_data.shape[2]\n",
    "    opt = Adam(learning_rate = learning_rate)\n",
    "\n",
    "    # Build model\n",
    "    inputs = Input(shape = (window_size, number_of_features))\n",
    "    # Encoder\n",
    "    encoded = LSTM(hidden_units[0], activation = activation_hidden, return_sequences = True)(inputs)\n",
    "    for i in range(0, n_layers_encoder):\n",
    "        if i == n_layers_encoder - 1:\n",
    "            encoded = LSTM(hidden_units[i], activation = activation_hidden)(encoded)\n",
    "            if dropout_rate != 0:\n",
    "                encoded = Dropout(dropout_rate)(encoded)\n",
    "        else:\n",
    "            encoded = LSTM(hidden_units[i], activation = activation_hidden, return_sequences = True)(encoded)\n",
    "            if dropout_rate != 0:\n",
    "                encoded = Dropout(dropout_rate)(encoded)\n",
    "    # Connection between the encoder and decoder\n",
    "    decoded = RepeatVector(window_size)(encoded)\n",
    "    # Decoder\n",
    "    decoded = LSTM(hidden_units[n_layers_encoder+1], activation = activation_hidden, return_sequences = True)(decoded)\n",
    "    if dropout_rate != 0:\n",
    "        decoded = Dropout(dropout_rate)(decoded)\n",
    "    for i in range(0, n_layers_decoder):\n",
    "        decoded = LSTM(hidden_units[n_layers_encoder+i+2], activation = activation_hidden, return_sequences = True)(decoded)\n",
    "        if dropout_rate != 0:\n",
    "            decoded = Dropout(dropout_rate)(decoded)\n",
    "    decoded = TimeDistributed(Dense(number_of_features, activation = activation_dense))(decoded) \n",
    "    \n",
    "    # Define loss\n",
    "    loss_metric = tf.keras.losses.MeanSquaredError()\n",
    "    if metric == 'mse':\n",
    "        loss_metric = tf.keras.losses.MeanSquaredError()\n",
    "    elif metric == 'mae':\n",
    "        loss_metric = tf.keras.losses.MeanAbsoluteError()\n",
    "        \n",
    "    # Compile the model\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer = opt, loss = loss_metric)\n",
    "                        \n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 50, verbose = 1, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "    # Train model\n",
    "    if val_data is not None:\n",
    "        history = autoencoder.fit(\n",
    "            train_data, train_data,\n",
    "            epochs = n_epochs,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = False,\n",
    "            validation_data = (val_data, val_data),\n",
    "            callbacks = [early_stopping]\n",
    "        )\n",
    "    else:\n",
    "        history = autoencoder.fit(\n",
    "            train_data, train_data,\n",
    "            epochs = n_epochs,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = False\n",
    "        )\n",
    "    \n",
    "    model_path = 'lstm/' + str(n_layers_encoder) + '_' + str(n_layers_decoder) + '_' + str(hidden_units[0]) + '_' + str(hidden_units[len(hidden_units)-1]) + '_' + str(activation_hidden) + '_' + str(activation_dense) + '_' + str(dropout_rate).replace('.', '') + '_' + str(learning_rate).replace('.', '') + '_' + str(n_epochs) + '_' + str(metric) + '_' + str(batch_size)\n",
    "\n",
    "    # Save history\n",
    "    if plot:\n",
    "        plt.figure(figsize = (10, 5))\n",
    "        plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        plt.tight_layout()\n",
    "        loss_save_path = 'losses/' + model_path\n",
    "        plt.savefig(loss_save_path + '.png')\n",
    "        plt.close()\n",
    "        \n",
    "    # Save model\n",
    "    if save:\n",
    "        model_save_path = 'models/' + model_path + '.pkl'\n",
    "        with open(model_save_path, 'wb') as file:\n",
    "            pickle.dump(autoencoder, file)\n",
    "\n",
    "    return history, autoencoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29962cb9fa4251cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
